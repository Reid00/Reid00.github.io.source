---
title: "MIT6.824 2022 Raft Lab2A Leader Election"
date: 2023-02-09T17:46:35+08:00
lastmod: 2023-02-09T17:46:35+08:00
author: ["Reid"]
categories: 
- Storage
- Raft
tags: 
- Raft
- MIT6.824
- Consensus
- 共识算法
keyword:
- Storage
- Raft
- MIT6.824
- Consensus
- 共识算法
description: ""
weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序
slug: MIT6.824-2022-Raft-Lab2A-Leader-Election
draft: false # 是否为草稿
comments: true
showToc: true # 显示目录
TocOpen: false # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示当前路径
cover:
    image: ""
    caption: ""
    alt: ""
    relative: false
---

## 介绍
- [论文简单介绍](20230209-MIT6.824-2022-Raft-介绍.md)
## 流程梳理
整体逻辑, 从 `ticker` goroutine 开始,启动两个Timer, `ElectionTimer` 和 `HeartbeatTimer`. 如果某个raft 节点election timeout,则会触发leader election, 调用`StartElection` 方法. `StartElection` 中发送 `RequestVote RPC`, 根据ReqestVote Response 判断是否收到选票,决定是否成为`Leader`。

如果某个节点,收到大多数节点的选票,成为`Leader` 要通过发送`Heartbeat` 即空LogEntry 的`AppendEntries RPC` 来告诉其他节点自己的 `Leader` 地位。

所以Lab2A 中,主要实现 `RequestVote`, `AppendEntries` 的逻辑。

## 相关函数解析
```go
type Raft struct {
	mu        sync.RWMutex        // Lock to protect shared access to this peer's state
	peers     []*labrpc.ClientEnd // RPC end points of all peers
	persister *Persister          // Object to hold this peer's persisted state
	me        int                 // this peer's index into peers[]
	dead      int32               // set by Kill()

	// Your data here (2A, 2B, 2C).
	// Look at the paper's Figure 2 for a description of what
	// state a Raft server must maintain.

	// 2A
	state          NodeState
	currentTerm    int
	votedFor       int
	electionTimer  *time.Timer
	heartbeatTimer *time.Timer

	// 2B
	logs        []Entry // the first is dummy entry which contains LastSnapshotTerm, LastSnapshotIndex and nil Command
	commitIndex int
	lastApplied int
	nextIndex   []int
	matchIndex  []int

	applyCh        chan ApplyMsg
	applyCond      *sync.Cond   // used to wakeup applier goroutine after committing new entries
	replicatorCond []*sync.Cond // used to signal replicator goroutine to batch replicating entries
}

func (rf *Raft) RequestVote(req *RequestVoteRequest, resp *RequestVoteResponse) {
	// Your code here (2A, 2B).
	// 2A
	rf.mu.Lock()
	defer rf.mu.Unlock()
	defer rf.persist()
	defer DPrintf("[RequestVote]-{Node %v}'s state is {state %v,term %v,commitIndex %v,lastApplied %v,firstLog %v,lastLog %v} before processing requestVoteRequest %v and reply requestVoteResponse %v",
		rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), req, resp)

	if req.Term < rf.currentTerm || (req.Term == rf.currentTerm && rf.votedFor != -1 && rf.votedFor != req.CandidateId) {
		resp.Term, resp.VoteGranted = rf.currentTerm, false
		return
	}

	if req.Term > rf.currentTerm {
		rf.ChangeState(StateFollower)
		rf.currentTerm, rf.votedFor = req.Term, -1
	}

	// 2A 可以先不实现
	if !rf.isLogUpToDate(req.LastLogTerm, req.LastLogIndex) {
		resp.Term, resp.VoteGranted = rf.currentTerm, false
		return
	}

	rf.votedFor = req.CandidateId
	rf.electionTimer.Reset(RandomizedElectionTimeout())
	resp.Term, resp.VoteGranted = rf.currentTerm, true
}
```
