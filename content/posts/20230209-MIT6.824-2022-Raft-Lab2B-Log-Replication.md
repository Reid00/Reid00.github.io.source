---
title: "MIT6.824 2022 Raft Lab2B Log Replication"
date: 2023-02-09T17:47:36+08:00
lastmod: 2023-02-09T17:47:36+08:00
author: ["Reid"]
categories: 
- Storage
- Raft
tags: 
- Raft
- MIT6.824
- Consensus
- 共识算法
keyword:
- Storage
- Raft
- MIT6.824
- Consensus
- 共识算法
description: ""
weight: # 输入1可以顶置文章，用来给文章展示排序，不填就默认按时间排序
slug: MIT6.824-2022-Raft-Lab2B-Log-Replication
draft: false # 是否为草稿
comments: true
showToc: true # 显示目录
TocOpen: false # 自动展开目录
hidemeta: false # 是否隐藏文章的元信息，如发布日期、作者等
disableShare: true # 底部不显示分享栏
showbreadcrumbs: true #顶部显示当前路径
cover:
    image: ""
    caption: ""
    alt: ""
    relative: false
---
## 流程梳理
相关的RPC 在[Raft0](https://reid00.github.io/posts/mit6.824-2022-raft-%E4%BB%8B%E7%BB%8D/) 中已经介绍, 这里不再赘述。
启动的Goroutine：
- `ticker`  一个，用于监听 Election Timeout 或者Heartbeat Timeout
- `applier` 一个，监听 leader commit 之后，把log 发送到ApplyCh，然后从applyCh 中持久化到本地
- `replicator ` n-1 个，每一个对应一个 peer。监听心跳广播命令，仅在节点为 Leader 时工作, 唤醒条件变量。接收到命令后，向对应的 peer 发送 AppendEntries RPC。
![lab 2b code summary](https://cdn.staticaly.com/gh/Reid00/image-host@main/20230203/image.6t8huvb8nsg0.webp)


### 快速恢复(Fast Backup)
在前面（7.1）介绍的日志恢复机制中，如果Log有冲突，Leader每次会回退一条Log条目。 这在许多场景下都没有问题。但是在某些现实的场景中，至少在Lab2的测试用例中，每次只回退一条Log条目会花费很长很长的时间。所以，现实的场景中，可能一个Follower关机了很长时间，错过了大量的AppendEntries消息。这时，Leader重启了。按照Raft论文中的图2，如果一个Leader重启了，它会将所有Follower的nextIndex设置为Leader本地Log记录的下一个槽位（7.1有说明）。所以，如果一个Follower关机并错过了1000条Log条目，Leader重启之后，需要每次通过一条RPC来回退一条Log条目来遍历1000条Follower错过的Log记录。这种情况在现实中并非不可能发生。在一些不正常的场景中，假设我们有5个服务器，有1个Leader，这个Leader和另一个Follower困在一个网络分区。但是这个Leader并不知道它已经不再是Leader了。它还是会向它唯一的Follower发送AppendEntries，因为这里没有过半服务器，所以没有一条Log会commit。在另一个有多数服务器的网络分区中，系统选出了新的Leader并继续运行。旧的Leader和它的Follower可能会记录无限多的旧的任期的未commit的Log。当旧的Leader和它的Follower重新加入到集群中时，这些Log需要被删除并覆盖。可能在现实中，这不是那么容易发生，但是你会在Lab2的测试用例中发现这个场景。

所以，为了更快的恢复日志，Raft论文在5.3结尾处，对这种方法有了一些模糊的描述。原文有些晦涩，在这里我会以一种更好的方式，尝试解释论文中有关快速恢复的方法。大致思想是，让Follower返回足够多的信息给Leader，这样Leader可以以`任期（Term）为单位来回退`，`而不用每次只回退一条Log条目`。所以现在，在恢复Follower的Log时，如果Leader和Follower的Log不匹配，Leader只需要对不同任期发生一条AEs，而不需要对每个不通Log条目发送一条AEs。这是一种加速策略，当然也可以有别的日志恢复的加速策略。

我将可能出现的场景分成3类，为了简化，这里只画出一个Leader（S2）和一个Follower（S1），S2将要发送一条任期号为6的AppendEntries消息给Follower。
- 场景1：S1(Follower)没有任期6的任何Log，因此我们需要回退一整个任期的Log。

![scenario](https://cdn.staticaly.com/gh/Reid00/image-host@main/20230117/image.5vhjr3670to0.webp)

- 场景2：S1收到了任期4的旧Leader的多条Log，但是作为新Leader，S2只收到了一条任期4的Log。所以这里，我们需要覆盖S1中有关旧Leader的一些Log。

![scenario](https://cdn.staticaly.com/gh/Reid00/image-host@main/20230117/image.75o42ybpazo0.webp)

- 场景3: S1与S2的Log不冲突，但是S1缺失了部分S2中的Log

![scenario](https://cdn.staticaly.com/gh/Reid00/image-host@main/20230117/image.29pfjgga39j4.webp)

可以让Follower在回复Leader的AppendEntries消息中，携带3个额外的信息，来加速日志的恢复。这里的回复是指，Follower因为Log信息不匹配，拒绝了Leader的AppendEntries之后的回复。这里的三个信息是指：
- XTerm: 这个是Follower中与Leader冲突的Log对应的任期号。在之前（7.1）有介绍Leader会在prevLogTerm中带上本地Log记录中，前一条Log的任期号。如果Follower在对应位置的任期号不匹配，它会拒绝Leader的AppendEntries消息，并将自己的任期号放在XTerm中。如果Follower在对应位置没有Log，那么这里会返回 -1。
- XIndex: 这个是Follower中，对应任期号为XTerm的第一条Log条目的槽位号。
- XLen: 如果Follower在对应位置没有Log，那么XTerm会返回-1，XLen表示空白的Log槽位数。

我们再来看这些信息是如何在上面3个场景中，帮助Leader快速回退到适当的Log条目位置。
- 场景1: Follower（S1）会返回XTerm=5，XIndex=2。Leader（S2）发现自己没有任期5的日志，它会将自己本地记录的，S1的nextIndex设置到XIndex，也就是S1中，任期5的第一条Log对应的槽位号。所以，如果Leader完全没有XTerm的任何Log，那么它应该回退到XIndex对应的位置（这样，Leader发出的下一条AppendEntries就可以一次覆盖S1中所有XTerm对应的Log）
- 场景2： Follower（S1）会返回XTerm=4，XIndex=1。Leader（S2）发现自己其实有任期4的日志，它会将自己本地记录的S1的nextIndex设置到本地在XTerm位置的Log条目后面，也就是槽位2。下一次Leader发出下一条AppendEntries时，就可以一次覆盖S1中槽位2和槽位3对应的Log。
- 场景3: Follower（S1）会返回XTerm=-1，XLen=2。这表示S1中日志太短了，以至于在冲突的位置没有Log条目，Leader应该回退到Follower最后一条Log条目的下一条，也就是槽位2，并从这开始发送AppendEntries消息。槽位2可以从XLen中的数值计算得到。

在本次的实现中以Term 为单位返回，不在一个一个Index 自减。这需要添加 `ConflicTerm`, `ConflictIndex` 字段 去记录出现冲突的位置和任期。然后在 HanleAppendEntries RPC 中，在 Leader 的log
中检查 `ConflictIndex` 位置的日志一致性。

### 为什么Raft协议不能提交之前任期的日志？
[查看](https://reid00.github.io/posts/%E4%B8%BA%E4%BB%80%E4%B9%88raft%E5%8D%8F%E8%AE%AE%E4%B8%8D%E8%83%BD%E6%8F%90%E4%BA%A4%E4%B9%8B%E5%89%8D%E4%BB%BB%E6%9C%9F%E7%9A%84%E6%97%A5%E5%BF%97/)

## 函数解析
```go

func (rf *Raft) AppendEntries(req *AppendEntriesReq, resp *AppendEntriesResp) {
	rf.mu.Lock()
	defer rf.mu.Unlock()
	defer rf.persist()
	defer DPrintf("[AppendEntries]- {Node: %v}'s state is {state %v, term %v, commitIndex %v, lastApplied %v, firstLog %v, lastLog %v} before processing AppendEntriesRequest %v and reply AppendEntries %v",
		rf.me, rf.state, rf.currentTerm, rf.commitIndex, rf.lastApplied, rf.getFirstLog(), rf.getLastLog(), req, resp)

	// 如果发现来自leader的rpc中的term比当前peer要小,
	// 说明是该RPC 来自旧的term(leader)，|| 或者 当前leader 需要更新 不处理
	if req.Term < rf.currentTerm {
		resp.Term, resp.Success = rf.currentTerm, false
		return
	}

	// 一般来讲,在vote的时候已经将currentTerm和leader同步
	// 不过,有些peer暂时的掉线或者其他一些情况重连以后,会发现term和leader不一样
	// 以收到大于自己的term的rpc也是第一时间同步.而且要将votefor重新设置为-1
	// 等待将来选举 (说明这个peer 不是之前election 中投的的marjority)
	if req.Term > rf.currentTerm {
		rf.currentTerm, rf.votedFor = req.Term, -1
	}

	rf.ChangeState(StateFollower)
	rf.electionTimer.Reset(RandomizedElectionTimeout())

	// PrevLogIndex 比rf 当前的第一个Log index 还要小
	if req.PrevLogIndex < rf.getFirstLog().Index {
		resp.Term, resp.Success = 0, false
		DPrintf("[AppendEntries] - {Node: %v} receives unexpected AppendEntriesRequest %v from {Node: %v} because prevLogIndex %v < firstLogIndex %v",
			rf.me, req, req.LeaderId, req.PrevLogIndex, rf.getFirstLog().Index)
		return
	}

	if !rf.matchLog(req.PrevLogTerm, req.PrevLogIndex) {
		// 日志的一致性检查失败后，递归找到需要追加日志的位置
		resp.Term, resp.Success = rf.currentTerm, false
		lastIndex := rf.getLastLog().Index

		if lastIndex < req.PrevLogIndex {
			// lastIndex 和 nextIndex[peer] 之间有空洞 scenario3
			// follower 在nextIndex[peer] 没有log
			resp.ConflictTerm = -1
			resp.ConflictIndex = lastIndex + 1
		} else {
			// scenario2, 1
			// 以任期为单位进行回退
			firstIndex := rf.getFirstLog().Index
			resp.ConflictTerm = rf.logs[req.PrevLogIndex-firstIndex].Term
			index := req.PrevLogIndex - 1
			for index >= firstIndex && rf.logs[index-firstIndex].Term == resp.ConflictTerm {
				index--
			}
			resp.ConflictIndex = index
		}
		return
	}

	firstIndex := rf.getFirstLog().Index
	for i, entry := range req.Entries {
		// mergeLog
		// 添加的日志索引位置 比Follower 日志相同 直接添加 此处用大于等于，实际只有==
		// || 要添加的日志索引位置在 Follower 中的任期和AE RPC 中的Term 冲突
		if entry.Index-firstIndex >= len(rf.logs) || rf.logs[entry.Index-firstIndex].Term != entry.Term {
			rf.logs = shrinkEntriesArray(append(rf.logs[:entry.Index-firstIndex], req.Entries[i:]...))
			break
		}
	}

	rf.advanceCommitIndexForFollower(req.LeaderComment)

	resp.Term, resp.Success = rf.currentTerm, true
}
```